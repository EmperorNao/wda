{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn import model_selection, ensemble, metrics, cluster\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "\n",
    "def embed_bert_cls(text, model, tokenizer):\n",
    "    t = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n",
    "\n",
    "    embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "    embeddings = torch.nn.functional.normalize(embeddings)\n",
    "    return embeddings[0].cpu().numpy()\n",
    "\n",
    "\n",
    "def rubert_embeddings(s: pd.Series) -> np.ndarray:\n",
    "    return np.vstack(s.map(partial(embed_bert_cls, model=model, tokenizer=tokenizer)).values)\n",
    "\n",
    "\n",
    "def umap_embeddings(X: np.ndarray):\n",
    "    normalized_embeddings = (X - X.mean(0)) / X.std(0)\n",
    "    return umap.UMAP(\n",
    "        random_state=100,\n",
    "        n_neighbors=10,\n",
    "        n_components=3,\n",
    "        n_jobs=1,\n",
    "        metric=\"cosine\",\n",
    "        min_dist=0.1,\n",
    "    ).fit_transform(normalized_embeddings)\n",
    "\n",
    "\n",
    "def optics_clusterize(X: np.ndarray) -> np.ndarray:\n",
    "    normalized_embeddings = (X - X.mean(0)) / X.std(0)\n",
    "    return cluster.OPTICS(metric=\"euclidean\").fit(normalized_embeddings).labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example usage: df_train_data can be obtained like this (just patch csv paths):\n",
    "df_train_groups = pd.read_csv(\"/kaggle/input/web-document-analysis/train_groups.csv\")\n",
    "df_test_groups = pd.read_csv(\"/kaggle/input/web-document-analysis/test_groups.csv\")\n",
    "df_docs_titles = pd.read_csv(\"/kaggle/input/web-document-analysis/docs_titles.tsv\", delimiter=\"\\t\")\n",
    "\n",
    "df_train_data = df_train_groups.merge(\n",
    "    df_docs_titles,\n",
    "    on=\"doc_id\",\n",
    "    how=\"inner\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_samples = df_train_data[df_train_data.group_id == 66].copy()\n",
    "\n",
    "rubert_embeddings_train = rubert_embeddings(df_train_samples[\"title\"])\n",
    "umap_embeddings_train = umap_embeddings(rubert_embeddings_train)\n",
    "optics_labels_train = optics_clusterize(rubert_embeddings_train)\n",
    "\n",
    "df_train_samples[\"cluster_label\"] = optics_labels_train\n",
    "df_train_samples[\"cluster_label\"] = df_train_samples[\"cluster_label\"].map(str)\n",
    "\n",
    "df_train_samples[\"x\"] = umap_embeddings_train[:, 0]\n",
    "df_train_samples[\"y\"] = umap_embeddings_train[:, 1]\n",
    "df_train_samples[\"z\"] = umap_embeddings_train[:, 2]\n",
    "df_train_samples[\"target_name\"] = df_train_samples[\"target\"].map(str)\n",
    "\n",
    "px.scatter_3d(\n",
    "    df_train_samples,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    z=\"z\",\n",
    "    symbol=\"target_name\",\n",
    "    color=\"cluster_label\",\n",
    "    template=\"plotly_dark\",\n",
    "    hover_data=\"title\",\n",
    ").show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
